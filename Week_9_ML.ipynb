{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HYLteLeRpVhE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N3TRLN8ApY1w",
        "outputId": "1c370ee0-e0a2-4883-c42c-2111a1d8a60e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = '/content/shakespeare (1).txt'"
      ],
      "metadata": {
        "id": "CzCMzjHLpawU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'r').read()"
      ],
      "metadata": {
        "id": "kJTMCorLpn3M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKjX_xV-ptj9",
        "outputId": "c12f8c09-6936-4925-b7fe-1276064d2bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uweuup5pvsH",
        "outputId": "492e9776-0d6c-4c59-c1ea-f085de39f589"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "MZnVU7EhpyWw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltb9IbBWp0vF",
        "outputId": "5e0dd1e3-f566-4b1b-e92f-e5751003f2ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " 'a': 55,\n",
              " 'b': 56,\n",
              " 'c': 57,\n",
              " 'd': 58,\n",
              " 'e': 59,\n",
              " 'f': 60,\n",
              " 'g': 61,\n",
              " 'h': 62,\n",
              " 'i': 63,\n",
              " 'j': 64,\n",
              " 'k': 65,\n",
              " 'l': 66,\n",
              " 'm': 67,\n",
              " 'n': 68,\n",
              " 'o': 69,\n",
              " 'p': 70,\n",
              " 'q': 71,\n",
              " 'r': 72,\n",
              " 's': 73,\n",
              " 't': 74,\n",
              " 'u': 75,\n",
              " 'v': 76,\n",
              " 'w': 77,\n",
              " 'x': 78,\n",
              " 'y': 79,\n",
              " 'z': 80,\n",
              " '|': 81}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "metadata": {
        "id": "lMLjkfFfp2eD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq2NUkRmp43T",
        "outputId": "43fbc83e-c48f-469d-cf8a-7d01f923f5ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
              "       'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
              "       'x', 'y', 'z', '|'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "metadata": {
        "id": "HOkWehN0p71i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXHFA_7Op-VH",
        "outputId": "c53688b3-a88a-4668-9d0a-07d14ccac89a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 50, 59, 73])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = text[:20]\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-AwRb7hMp_o3",
        "outputId": "34ea5c2a-c487-4c42-934d-a4dbebb9e3fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFuAvDrBqBUB",
        "outputId": "e23a10b1-b712-46e5-c255-d9b5365012f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul9RE_AbqD1t",
        "outputId": "745c0f87-dc6c-4cc4-9f80-30efcc425816"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line = \"From fairest creatures we desire increase\""
      ],
      "metadata": {
        "id": "Uc2TMYdIqGiC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97kzkQMUqIVF",
        "outputId": "6b9ed287-4440-48a0-fb2b-1e0765dbd38a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "That thereby beauty's rose might never die,\n",
        "But as the riper should by time decease,\"\"\""
      ],
      "metadata": {
        "id": "s3NKWBH9qJ3q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(part_stanza)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIGNKeldqMM7",
        "outputId": "86517205-214c-4039-9e2c-f222e54e9603"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 120"
      ],
      "metadata": {
        "id": "FubwKYXdqN48"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq = len(text)//(seq_len+1)"
      ],
      "metadata": {
        "id": "SPdKEMxkqQxx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiobdwZhqSlr",
        "outputId": "77a081c3-62a2-446f-f451-c11446757e15"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8665"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "for i in char_dataset.take(500):\n",
        "\n",
        "   print(ind_to_char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DzLLC4hqT_G",
        "outputId": "a969f558-cf93-4e6e-b7b5-20e81da67d8b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "ufG_TyWbqXBn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt"
      ],
      "metadata": {
        "id": "bYrZaoeeqeEL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "eWb8cPILqgIc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "# There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNpfokjmqlEP",
        "outputId": "07d25404-1c54-4ee2-bdea-4e2cbbf9c1a7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 72 69 67  1 60 55 63 72 59 73 74  1 57 72 59 55 74 75 72 59 73\n",
            "  1 77 59  1 58 59 73 63 72 59  1 63 68 57 72 59 55 73 59  8  0  1  1 45\n",
            " 62 55 74  1 74 62 59 72 59 56 79  1 56 59 55 75 74 79  5 73  1 72 69 73\n",
            " 59  1 67 63 61 62 74  1 68 59 76 59 72  1 58 63 59  8  0  1  1 27 75 74]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 72 69 67  1 60 55 63 72 59 73 74  1 57 72 59 55 74 75 72 59 73  1\n",
            " 77 59  1 58 59 73 63 72 59  1 63 68 57 72 59 55 73 59  8  0  1  1 45 62\n",
            " 55 74  1 74 62 59 72 59 56 79  1 56 59 55 75 74 79  5 73  1 72 69 73 59\n",
            "  1 67 63 61 62 74  1 68 59 76 59 72  1 58 63 59  8  0  1  1 27 75 74  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "batch_size = 128\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles el\n",
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "Tbs0ifvOqshJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3WWhr9uqwZQ",
        "outputId": "904217c1-c853-46f4-c8cf-db5a353977bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "pxGACqlVqxt-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ],
      "metadata": {
        "id": "H6cF6tXSqz4g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "oeuALMnKq2mU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCg8G4epq4y1",
        "outputId": "58070a7b-8e6e-40db-eaf7-1c428d9af96d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.src.losses.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, ignore_class=None, axis=-1)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Args:\n",
            "        y_true: Ground truth values.\n",
            "        y_pred: The predicted values.\n",
            "        from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "            default, we assume that `y_pred` encodes a probability distribution.\n",
            "        ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "            loss computation. This is useful, for example, in segmentation\n",
            "            problems featuring a \"void\" class (commonly -1 or 255) in\n",
            "            segmentation maps. By default (`ignore_class=None`), all classes are\n",
            "            considered.\n",
            "        axis: Defaults to `-1`. The dimension along which the entropy is\n",
            "            computed.\n",
            "    \n",
            "    Returns:\n",
            "        Sparse categorical crossentropy loss value.\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true, y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n"
      ],
      "metadata": {
        "id": "2Q3TRI8Aq6PE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    # Define Input layer with batch size for stateful RNN\n",
        "    inputs = Input(batch_shape=(batch_size, None), name=\"input_layer\")\n",
        "\n",
        "    x = Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
        "    x = GRU(rnn_neurons,\n",
        "            return_sequences=True,\n",
        "            stateful=True,\n",
        "            recurrent_initializer='glorot_uniform')(x)\n",
        "    outputs = Dense(vocab_size)(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    return model"
      ],
      "metadata": {
        "id": "kb9a1-QTq99H"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(\n",
        "vocab_size = vocab_size,\n",
        "embed_dim = embed_dim,\n",
        "rnn_neurons = rnn_neurons,\n",
        "batch_size = batch_size)"
      ],
      "metadata": {
        "id": "CpdMeT4drDVn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "eG30PzTKrE84",
        "outputId": "397e97f5-0949-4cd2-cfbb-77dff47d5852"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m5,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)           │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)             │          \u001b[38;5;34m84,214\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">84,214</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,450,638\u001b[0m (13.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,450,638</span> (13.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,450,638\u001b[0m (13.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,450,638</span> (13.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"<=== (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRLXpm48srs5",
        "outputId": "65079803-05f4-46aa-83a4-4e418ecfc8d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 82) <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSITTfHEtXrT",
        "outputId": "e1e35ded-e3bc-4bc4-e3f6-34fcfb69b2e0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 82), dtype=float32, numpy=\n",
              "array([[[ 4.39414661e-03, -5.69357583e-03, -4.50037373e-03, ...,\n",
              "         -3.82557139e-03, -1.10844627e-03, -4.63541970e-03],\n",
              "        [ 2.18575262e-03, -3.52036091e-03, -5.67104714e-03, ...,\n",
              "          1.73152337e-04,  1.84504618e-03,  1.41693873e-03],\n",
              "        [-4.82340483e-03, -8.51976313e-03, -3.07584531e-03, ...,\n",
              "         -3.54486139e-04,  6.66978827e-04,  7.53199495e-03],\n",
              "        ...,\n",
              "        [ 5.70557266e-03, -1.45323121e-03,  1.34303560e-03, ...,\n",
              "          4.80644358e-03,  2.27917032e-03,  6.02803193e-03],\n",
              "        [ 8.18385184e-03,  1.32051413e-04, -2.56036175e-04, ...,\n",
              "          6.14866847e-03, -4.69826581e-03,  3.64655745e-03],\n",
              "        [ 3.07647558e-03, -4.43212979e-04,  2.19128910e-03, ...,\n",
              "          2.15693470e-03, -5.18550910e-03, -1.94367405e-03]],\n",
              "\n",
              "       [[ 5.01759676e-03,  3.68522742e-04, -4.83711949e-04, ...,\n",
              "          4.94126556e-03, -5.85314957e-03,  1.07577897e-03],\n",
              "        [-6.55132998e-03,  7.94780441e-03,  8.50571971e-03, ...,\n",
              "          4.68771812e-03,  2.21406249e-03,  1.94765802e-03],\n",
              "        [-2.63559748e-03,  8.31942819e-03,  4.85039462e-04, ...,\n",
              "          4.42535244e-03,  2.57895235e-03, -3.15173366e-03],\n",
              "        ...,\n",
              "        [ 7.25399889e-03, -1.04587071e-03,  1.04720015e-02, ...,\n",
              "          1.21479330e-03,  3.91494902e-03, -4.77751391e-03],\n",
              "        [ 7.58477906e-03, -5.24967117e-03,  6.06619706e-03, ...,\n",
              "         -6.18476304e-04,  1.86785182e-03,  1.40822388e-03],\n",
              "        [ 8.90694745e-03, -2.46298569e-03,  4.58168285e-03, ...,\n",
              "          4.84727975e-03, -3.80603084e-03,  1.37034149e-04]],\n",
              "\n",
              "       [[ 6.20929059e-03,  4.32125235e-04,  2.17674836e-03, ...,\n",
              "          2.75960797e-03, -1.37914601e-03, -2.40253704e-03],\n",
              "        [ 3.29126441e-03,  4.29525040e-03, -3.45682935e-03, ...,\n",
              "          2.84583378e-03, -2.33308296e-04, -6.31501619e-03],\n",
              "        [ 4.90376912e-03, -3.38668469e-03, -1.49403629e-03, ...,\n",
              "         -9.32672236e-04, -7.52065505e-04,  2.57054158e-03],\n",
              "        ...,\n",
              "        [ 3.13400314e-03, -6.08088588e-03, -6.35665376e-04, ...,\n",
              "          2.20528585e-04,  3.57087207e-04,  7.00429780e-03],\n",
              "        [-7.33329309e-03,  2.61337520e-03,  1.01579521e-02, ...,\n",
              "          2.80886609e-03,  5.91923390e-03,  6.10935362e-03],\n",
              "        [-3.12355673e-03,  4.45318362e-03,  2.16685049e-03, ...,\n",
              "          3.72948591e-03,  4.52627661e-03, -7.69782346e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 3.60275595e-03, -5.28116571e-03, -1.06822197e-04, ...,\n",
              "         -1.25955394e-03, -8.23659881e-04,  4.64219926e-03],\n",
              "        [-1.57679699e-03, -7.18813564e-04, -5.89494500e-03, ...,\n",
              "         -4.31229128e-03, -2.77490867e-03, -1.91593159e-03],\n",
              "        [ 4.51070955e-04, -2.50002416e-03, -3.52121214e-03, ...,\n",
              "          1.73297210e-03,  6.17137586e-04,  4.06067586e-03],\n",
              "        ...,\n",
              "        [ 3.47810477e-04,  3.98488948e-03, -8.85145087e-03, ...,\n",
              "          1.35898066e-03,  7.60831754e-04, -4.04698262e-03],\n",
              "        [ 3.30851460e-03, -3.16274585e-03, -4.92683798e-03, ...,\n",
              "         -1.86757219e-03, -3.55149532e-04,  3.68689885e-03],\n",
              "        [ 7.41911959e-03, -1.39190652e-03,  7.75903231e-04, ...,\n",
              "          1.43769232e-03, -5.10115526e-04, -1.11494132e-03]],\n",
              "\n",
              "       [[-3.65384715e-03, -1.26234628e-03, -5.34372171e-03, ...,\n",
              "         -1.08259881e-03, -4.17784974e-03,  1.61087653e-03],\n",
              "        [ 9.77377989e-04, -6.17369171e-03, -1.61889673e-03, ...,\n",
              "         -3.95389943e-04, -2.33968208e-03,  4.86737397e-03],\n",
              "        [-6.24239305e-03, -2.90347473e-03,  5.97935496e-03, ...,\n",
              "         -2.38144677e-03, -2.19208817e-03,  4.08663787e-03],\n",
              "        ...,\n",
              "        [ 4.10555396e-03, -2.61390698e-03,  2.39519309e-03, ...,\n",
              "          6.61601173e-03,  3.08602001e-03,  5.79356914e-03],\n",
              "        [ 8.46999756e-04, -2.20431481e-03, -3.29570309e-03, ...,\n",
              "         -4.73742431e-04,  3.77113977e-03,  5.33054816e-03],\n",
              "        [ 3.05630942e-03, -6.36083027e-03, -2.78667198e-03, ...,\n",
              "         -2.20060721e-03,  2.37117917e-03,  7.03048194e-03]],\n",
              "\n",
              "       [[ 5.01759676e-03,  3.68522742e-04, -4.83711949e-04, ...,\n",
              "          4.94126556e-03, -5.85314957e-03,  1.07577897e-03],\n",
              "        [ 1.49026269e-03,  1.10078265e-03,  2.16658786e-03, ...,\n",
              "          6.00804202e-03, -3.18044680e-03,  2.50950991e-03],\n",
              "        [-7.79846357e-03,  6.61697192e-03,  1.07501661e-02, ...,\n",
              "          5.82264457e-03,  4.31920681e-03,  4.66019986e-03],\n",
              "        ...,\n",
              "        [-1.40197738e-03, -3.65974335e-03,  2.49520340e-03, ...,\n",
              "          3.53684765e-04, -3.85865592e-03,  3.87398526e-03],\n",
              "        [-9.03757941e-03,  3.41014075e-03,  1.07162138e-02, ...,\n",
              "          2.25532427e-03,  2.93219369e-03,  6.02178462e-03],\n",
              "        [ 6.76641685e-06, -4.79990430e-03,  6.58752536e-03, ...,\n",
              "          2.00705486e-04,  1.48050138e-03,  9.46896337e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "metadata": {
        "id": "ugSNPNRFtgc8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwqG44G7tlFl",
        "outputId": "421a9efa-f935-496f-f4e6-e9dbe24f0c30"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[33],\n",
              "       [60],\n",
              "       [24],\n",
              "       [52],\n",
              "       [41],\n",
              "       [28],\n",
              "       [26],\n",
              "       [38],\n",
              "       [73],\n",
              "       [36],\n",
              "       [81],\n",
              "       [29],\n",
              "       [55],\n",
              "       [ 1],\n",
              "       [63],\n",
              "       [62],\n",
              "       [40],\n",
              "       [53],\n",
              "       [66],\n",
              "       [45],\n",
              "       [38],\n",
              "       [15],\n",
              "       [24],\n",
              "       [49],\n",
              "       [53],\n",
              "       [40],\n",
              "       [ 4],\n",
              "       [14],\n",
              "       [73],\n",
              "       [71],\n",
              "       [65],\n",
              "       [36],\n",
              "       [69],\n",
              "       [52],\n",
              "       [79],\n",
              "       [ 9],\n",
              "       [45],\n",
              "       [75],\n",
              "       [22],\n",
              "       [34],\n",
              "       [75],\n",
              "       [ 9],\n",
              "       [39],\n",
              "       [34],\n",
              "       [22],\n",
              "       [39],\n",
              "       [37],\n",
              "       [56],\n",
              "       [79],\n",
              "       [47],\n",
              "       [10],\n",
              "       [70],\n",
              "       [67],\n",
              "       [ 5],\n",
              "       [31],\n",
              "       [41],\n",
              "       [67],\n",
              "       [ 2],\n",
              "       [18],\n",
              "       [40],\n",
              "       [65],\n",
              "       [50],\n",
              "       [70],\n",
              "       [23],\n",
              "       [ 7],\n",
              "       [47],\n",
              "       [60],\n",
              "       [59],\n",
              "       [77],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [35],\n",
              "       [26],\n",
              "       [77],\n",
              "       [53],\n",
              "       [19],\n",
              "       [51],\n",
              "       [49],\n",
              "       [70],\n",
              "       [58],\n",
              "       [75],\n",
              "       [13],\n",
              "       [81],\n",
              "       [42],\n",
              "       [59],\n",
              "       [74],\n",
              "       [46],\n",
              "       [41],\n",
              "       [77],\n",
              "       [60],\n",
              "       [67],\n",
              "       [77],\n",
              "       [37],\n",
              "       [67],\n",
              "       [ 3],\n",
              "       [29],\n",
              "       [80],\n",
              "       [22],\n",
              "       [27],\n",
              "       [57],\n",
              "       [37],\n",
              "       [49],\n",
              "       [22],\n",
              "       [36],\n",
              "       [53],\n",
              "       [40],\n",
              "       [73],\n",
              "       [50],\n",
              "       [55],\n",
              "       [76],\n",
              "       [60],\n",
              "       [61],\n",
              "       [59],\n",
              "       [51],\n",
              "       [73],\n",
              "       [36],\n",
              "       [49],\n",
              "       [58],\n",
              "       [35],\n",
              "       [81]])>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "JlNqcMG4tnLz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwx2LQSDtp0r",
        "outputId": "6a5162c6-afac-401d-a389-d99ca1f2b0d4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33, 60, 24, 52, 41, 28, 26, 38, 73, 36, 81, 29, 55,  1, 63, 62, 40,\n",
              "       53, 66, 45, 38, 15, 24, 49, 53, 40,  4, 14, 73, 71, 65, 36, 69, 52,\n",
              "       79,  9, 45, 75, 22, 34, 75,  9, 39, 34, 22, 39, 37, 56, 79, 47, 10,\n",
              "       70, 67,  5, 31, 41, 67,  2, 18, 40, 65, 50, 70, 23,  7, 47, 60, 59,\n",
              "       77,  1,  1, 35, 26, 77, 53, 19, 51, 49, 70, 58, 75, 13, 81, 42, 59,\n",
              "       74, 46, 41, 77, 60, 67, 77, 37, 67,  3, 29, 80, 22, 27, 57, 37, 49,\n",
              "       22, 36, 53, 40, 73, 50, 55, 76, 60, 61, 59, 51, 73, 36, 49, 58, 35,\n",
              "       81])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALWFns9TttfN",
        "outputId": "cf3fa104-ec41-46d0-daf8-974c591afad8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "uy\n",
            "    my fortunes.\n",
            "  OLIVER. And what wilt thou do? Beg, when that is spent? Well, sir,\n",
            "    get you in. I will not long\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "Hf>[PCAMsK|Da ihO]lTM4>X]O&3sqkKo[y-Tu;Iu-NI;NLbyV.pm'FPm!7OkYp<)Vfew  JAw]8ZXpdu2|QetUPwfmwLm\"Dz;BcLX;K]OsYavfgeZsKXdJ|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "Il1-9tqvtwY7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7m_H74Dt3e0",
        "outputId": "3a1e4d16-ae2a-4764-f3da-1b5a288cc9f3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 133ms/step - loss: 3.9071\n",
            "Epoch 2/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - loss: 2.4007\n",
            "Epoch 3/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 141ms/step - loss: 2.0973\n",
            "Epoch 4/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 1.9199\n",
            "Epoch 5/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - loss: 1.7755\n",
            "Epoch 6/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 151ms/step - loss: 1.6522\n",
            "Epoch 7/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - loss: 1.5601\n",
            "Epoch 8/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - loss: 1.4865\n",
            "Epoch 9/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 144ms/step - loss: 1.4344\n",
            "Epoch 10/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 151ms/step - loss: 1.3832\n",
            "Epoch 11/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 157ms/step - loss: 1.3475\n",
            "Epoch 12/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 148ms/step - loss: 1.3120\n",
            "Epoch 13/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - loss: 1.2849\n",
            "Epoch 14/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 142ms/step - loss: 1.2581\n",
            "Epoch 15/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 150ms/step - loss: 1.2332\n",
            "Epoch 16/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 154ms/step - loss: 1.2127\n",
            "Epoch 17/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 148ms/step - loss: 1.1890\n",
            "Epoch 18/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - loss: 1.1692\n",
            "Epoch 19/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 1.1469\n",
            "Epoch 20/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - loss: 1.1281\n",
            "Epoch 21/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 149ms/step - loss: 1.1081\n",
            "Epoch 22/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 145ms/step - loss: 1.0900\n",
            "Epoch 23/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - loss: 1.0657\n",
            "Epoch 24/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - loss: 1.0479\n",
            "Epoch 25/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 149ms/step - loss: 1.0264\n",
            "Epoch 26/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 147ms/step - loss: 1.0046\n",
            "Epoch 27/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 150ms/step - loss: 0.9824\n",
            "Epoch 28/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 147ms/step - loss: 0.9550\n",
            "Epoch 29/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - loss: 0.9352\n",
            "Epoch 30/30\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 143ms/step - loss: 0.9132\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x790d25cc1d90>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('shakespeare_gen.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZDv2Kqtt5CS",
        "outputId": "19ac170f-d61e-48dc-9550-1a9824056abc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "YcT-knM_vXYe"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)"
      ],
      "metadata": {
        "id": "myRr5ZzEvcEr"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('shakespeare_gen.h5')"
      ],
      "metadata": {
        "id": "AAnn9JiLvgdp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "f9pulmOyvjDv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "r1RTGdHOvk7b",
        "outputId": "3e9ac550-8088-4afb-ba96-7072b7721e01"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m5,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)             │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m)               │          \u001b[38;5;34m84,214\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">84,214</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,450,638\u001b[0m (13.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,450,638</span> (13.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,450,638\u001b[0m (13.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,450,638</span> (13.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "    '''\n",
        "    model: Trained Model to Generate Text\n",
        "    start_seed: Intial Seed text in string form\n",
        "    gen_size: Number of characters to generate\n",
        "    Basic idea behind this function is to take in some seed text, format it so\n",
        "    that it is in the correct shape for our network, then loop the sequence as\n",
        "    we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "    time series problems.\n",
        "    '''\n",
        "    # Number of characters to generate\n",
        "    num_generate = gen_size\n",
        "    # Vecotrizing starting seed text\n",
        "    input_eval = [char_to_ind[s] for s in start_seed]\n",
        "    # Expand to match batch format shape\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    # Empty list to hold resulting generated text\n",
        "    text_generated = []\n",
        "    # Temperature effects randomness in our resulting text\n",
        "    # The term is derived from entropy/thermodynamics.\n",
        "    # The temperature is used to effect probability of next characters.\n",
        "    # Higher probability == lesss surprising/ more expected\n",
        "    # Lower temperature == more surprising / less expected\n",
        "    temperature = temp\n",
        "    # Here batch size == 1\n",
        "    # model.reset_states() # Remove this line to solve the problem! The Functional model does not have reset_states attribute\n",
        "    for i in range(num_generate):\n",
        "        # Generate Predictions\n",
        "        predictions = model(input_eval)\n",
        "        # Remove the batch shape dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # Use a cateogircal disitribution to select the next character\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        # Pass the predicted charracter for the next input\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        # Transform back to character letter\n",
        "        text_generated.append(ind_to_char[predicted_id])\n",
        "    return (start_seed + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "FZ_QmHsvvpyS"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"flower\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbIzkzLpwVDL",
        "outputId": "3a343859-ace4-4648-82bf-ed991d23223c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowers a wife?\n",
            "  SILVIUS. I have one that speak of bites shoothen,\n",
            "    Which more than such followers a crossation\n",
            "    To ask 'gainst Princess.                       fold scarf as such\n",
            "    fellow, and would undont them-us, and never come hither;\n",
            "    And in that rade of faults I will Ture black'd, I know not whose bat for me; event\n",
            "    O the world knight thy dead with that shall be stol'n up.\n",
            "    I'll make an endman dirch we call be worth for Gilenum.\n",
            "    Fine to his figures for here above this head,\n",
            "    As if covering in rats that he is. Most now.\n",
            "  Mar. And in time to hangman that her woes Will you\n",
            "     mather but a minute bond and your firestin?\n",
            "  Readnest near he has no other might blow a sea-'t, AEDILE\n",
            "US. Fare thee hen? Rangain, well be answer'd with another boy\n",
            "                  'twas a conqueror familiar than liv'd\n",
            "    Baster, your helms will lature me farting for made:  \n",
            "    But what noirs you for love, I love more fruit.\n",
            "  FIRST SERVANT. But do not fled well for Rome. As I'll been\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJAN2ELawfPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}