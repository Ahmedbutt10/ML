{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09953b0-599d-4f8f-9b19-68c72d26a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed1fd8-29a1-475f-9000-3b313b58057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357f6b1-eb51-4726-aff8-e46320809cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls C:\\Users\\ma2747\\Downloads\\tensorflow-speech-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa38a3-b389-4b2c-924d-0c365eaf210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(r'C:\\Users\\ma2747\\Downloads\\tensorflow-speech-recognition-challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9098308-5c04-4f3a-b993-fd36cae7494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a69f93-72ba-402c-96e4-f24335dda8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the audio file\n",
    "train_audio_path = r'C:\\Users\\ma2747\\Downloads\\tensorflow-speech-recognition-challenge\\train\\audio'\n",
    "file_path = os.path.join(train_audio_path, 'yes', '0a7c2a8d_nohash_0.wav')\n",
    "\n",
    "# Load the audio file\n",
    "samples, sample_rate = librosa.load(file_path, sr=16000)\n",
    "\n",
    "# Plot the raw wave\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.set_title('Raw wave of ' + file_path)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.plot(np.linspace(0, len(samples) / sample_rate, len(samples)), samples)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9150e423-f037-4f03-8061-99b3b23ceecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(samples, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e65eb-c3a5-4126-bbbf-3db557dd1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb48517-37a6-4608-ab88-f45ae71323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "\n",
    "# Resample the audio\n",
    "samples_resampled = librosa.resample(samples, orig_sr=sample_rate, target_sr=new_sample_rate)\n",
    "\n",
    "# Play the resampled audio\n",
    "ipd.Audio(samples_resampled, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67476e6-1c74-449e-a8f5-03b78bc76962",
   "metadata": {},
   "outputs": [],
   "source": [
    " labels=os.listdir(train_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256298a-8d7f-412d-8bfb-b5edde22fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find count of each label and plot bar graph\n",
    "no_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    no_of_recordings.append(len(waves))\n",
    "#plot\n",
    "plt.figure(figsize=(30,5))\n",
    "index = np.arange(len(labels))\n",
    "plt.bar(index, no_of_recordings)\n",
    "plt.xlabel('Commands', fontsize=12)\n",
    "plt.ylabel('No of recordings', fontsize=12)\n",
    "plt.xticks(index, labels, fontsize=15, rotation=60)\n",
    "plt.title('No. of recordings for each command')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246b608-6be2-4989-b34c-41b9288f4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b46cbe-3eaa-4620-af2e-1a3f44ef7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_of_recordings=[]\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n",
    "        duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "plt.hist(np.array(duration_of_recordings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e3df5-0390-4c5f-93cf-b5af5885a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "train_audio_path = r'C:\\Users\\ma2747\\Downloads\\tensorflow-speech-recognition-challenge\\train\\audio'\n",
    "all_wave = []\n",
    "all_label = []\n",
    "\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(os.path.join(train_audio_path, label)) if f.endswith('.wav')]\n",
    "    \n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(os.path.join(train_audio_path, label, wav), sr=16000)\n",
    "        samples = librosa.resample(samples, orig_sr=sample_rate, target_sr=8000)\n",
    "        \n",
    "        if len(samples) == 8000:\n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea56a4-9ba9-48a4-9e2c-ab7639fa2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc076b-12e0-4e20-b398-c86ed4c0d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be6152-620a-4041-8e4a-2fa21389a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc8b73-9fe9-43a5-9344-ad5c1cde8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5757ac-689f-47e6-8d9e-641823b8badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6d470-1414-454a-954d-63b66a4d2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240c422-522e-4b5c-a3e1-f1db525e5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning\n",
    "import tensorflow.keras as keras\n",
    "#from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7db50-9706-4ccb-bd1b-40df93ad6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b2f6f1-b22e-4b24-8c67-e77edc694331",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(8000,1))\n",
    "#First Conv1D layer\n",
    "conv = layers.Conv1D(8,13, padding='valid', activation='relu',strides=1)(inputs)\n",
    "conv = layers.MaxPooling1D(3)(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "#Second Conv1D layer\n",
    "conv = layers.Conv1D(16, 11, padding='valid', activation='relu',strides=1)(conv)\n",
    "conv = layers.MaxPooling1D(3)(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "#Third Conv1D layer\n",
    "conv = layers.Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = layers.MaxPooling1D(3)(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "#Fourth Conv1D layer\n",
    "conv = layers.Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = layers.MaxPooling1D(3)(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "#Flatten layer\n",
    "conv = layers.Flatten()(conv)\n",
    "#Dense Layer 1\n",
    "conv = layers.Dense(256, activation='relu')(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "#Dense Layer 2\n",
    "conv = layers.Dense(128, activation='relu')(conv)\n",
    "conv = layers.Dropout(0.3)(conv)\n",
    "outputs = layers.Dense(len(labels), activation='softmax')(conv)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f7605-e2d8-426c-8f14-866db697ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92291593-d8d2-48a3-9c22-c3bde9b5940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397c54e-8e82-470e-8ab1-3c096be9d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early stopping callback\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "# Model checkpoint callback\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aad05f-29c6-4c9c-99ab-3b993490b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_tr, y_tr ,epochs=1, callbacks=[es,mc], batch_size=32,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786b19e-2719-4cd8-9492-1a5ba1afcb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c433ea-efad-43a8-a13f-c4880ea91cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256d6f9-708f-4af2-9854-cbcf6c1abbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio):\n",
    "    prob=model.predict(audio.reshape(1,8000,1))\n",
    "    index=np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03c01d-573f-4ccf-bccb-e354e5f6df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index=random.randint(0,len(x_val)-1)\n",
    "samples=x_val[index].ravel()\n",
    "print(\"Audio:\",classes[np.argmax(y_val[index])])\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
